# AGENTIC SYSTEM SUPER AUDIT
**Date:** November 17, 2025  
**Author:** GPT-5.1 Codex (cursor agent)  
**Scope:** ChatKit maritime research agent (functions/api/chatkit)

---

## 1. Executive Summary
- The incident query *‚Äúwhis is the big danish cargo vessel‚Äù* was routed through **verification mode only**, so the agent never launched multi-source Tavily research even though browsing was enabled. The underlying reason is that `classifyQuery` only returns `research` when both browsing is on **and** the query hits a high ‚Äútechnical depth‚Äù score (‚â•4). Comparative prompts without maintenance keywords never satisfy that condition, so the system is effectively ‚ÄúGemini-only‚Äù for 80‚Äì90% of traffic.
- Comparative reasoning, reflexion and gap-filling never fired because the heuristics require exact keywords: plan-and-solve only triggers on ‚Äúbiggest/largest‚Ä¶‚Äù (not ‚Äúbig‚Äù), and vessel detection requires either IMO/MMSI tokens or a name with digits. Result: generic prompts never enter the vessel pathway and miss IMO/owner/operator extraction entirely.
- Chain-of-thought is generated by GPT-4o but **the server intentionally drops every thinking/status SSE event** (`const EMIT_THINKING_EVENTS = false`). The stream parser simultaneously strips `<thinking>` chunks from the token stream, so the UI sees neither structured thoughts nor inline reasoning.
- Inline citations are being converted to `[N]` without links by `convertLegacyCitations`, which explains the ‚Äúnon-clickable‚Äù feedback from PMs. The formatter assumes the research panel shows URLs, but in chat mode the numbers become dead text.
- Modern AI copilots now provide explainability controls, orchestration across multi-modal data and red-teaming/robustness guarantees. The current agent lacks plan‚Üíact‚Üícritique loops, tool diversity (Gemini + Tavily only) and human-in-the-loop checkpoints, so it cannot compete with the latest maritime-specific assistants (Windward, OceanAI, Vibylabs, Marcura).

---

## 2. Failure Reconstruction
1. **User input:** `enableBrowsing: true`, query typo ‚Äúwhis is the big danish cargo vessel‚Äù.
2. **Classification:** 
   - `hasEntity` returns `false` because there is no IMO/MMSI and no digit-bearing vessel name.
   - `needsTechnicalDepth` is `false` (no maintenance keywords).
   - With browsing on but no entity/technical depth, the guardrail at lines 518‚Äì525 of `query-classification-rules.ts` forces **knowledge mode** and falls back to training data even though the user explicitly toggled research.
3. **Router fallback:** Later, `enableBrowsing` is ignored again because the ‚Äúsafety override‚Äù at lines 536‚Äì554 forces `verification` for any entity-like query when browsing is off. In this case `hasEntity` stays `false`, so we never even get deep research instrumentation.
4. **Gemini grounding:** Router executes Gemini search, streaming results to the synthesizer. Deep research only runs if (a) fewer than 3 sources are found or (b) evidence confidence is low; neither condition fired because Gemini returned ten results.
5. **Synthesis:** The `synthesizerNode` wraps the response with the zero-shot CoT prompt, but the downstream SSE handler strips `<thinking>` tokens and never emits the reasoning events, so the front-end shows a blank ‚Äúthinking‚Äù section.

---

## 3. Core Pipeline Diagnostics

### 3.1 Research mode is effectively unreachable
- `classifyQuery` only returns `research` when **browsing=true, `hasEntity`=true, `needsTechnicalDepth`=true, and `technicalDepthScore >= 4`** (lines 609‚Äì624). Comparative lookups (‚Äúbig vessel‚Äù, ‚Äúlargest port‚Äù) almost never contain the OEM/maintenance keywords required to score ‚â•4, so the agent stays in verification.

```609:625:functions/api/chatkit/query-classification-rules.ts
if (needsTechnicalDepth && hasEntity && technicalDepthScore >= 4) {
  return {
    mode: enableBrowsing ? 'research' : 'verification',
    preserveFleetcoreContext: true,
    enrichQuery: true,
    ...
  };
}
```

- **Impact:** The ‚ÄúOnline Research‚Äù toggle is a no-op for most users; they always get Gemini‚Äôs 5‚Äì10 snippets regardless of the switch. Evidence: the incident logs show `enableBrowsing: true` and 10 Gemini sources, but zero Tavily calls.
- **Fix:** Break out `research` mode selection from ‚Äútechnical depth‚Äù (e.g., compare vs. gather). A simpler rule‚Äî*if browsing is on and query is comparative or missing critical identifiers ‚Üí research*‚Äîwill actually honor the toggle. Also update the mode telemetry text (`mode_description['research']`) so engineering dashboards stop insisting it‚Äôs ‚Äúdisabled‚Äù.

### 3.2 Comparative detection misses ‚Äúbig/bigger‚Äù
- `selectCoTTechnique` only triggers plan-and-solve when the query contains `biggest|largest|smallest|best|compare|versus|vs`. The incident query uses ‚Äúbig‚Äù, so CoT stayed in zero-shot narrative mode and never ranked candidate vessels.

```291:305:functions/api/chatkit/synthetic-cot-engine.ts
if (/\b(biggest|largest|smallest|best|compare|versus|vs\.?)\b/i.test(query)) {
  return { technique: 'plan-solve', requiresComparison: true };
}
```

- **Fix:** Extend the regex with `big|bigger|longest|highest|tallest|more|less` and add NLP-based comparative detection (e.g., `compromise` on adjectives). Without this, most ‚Äúlargest/big‚Äù prompts degrade to generic vessel bios.

### 3.3 Vessel detection requires numbers ‚Üí reflexion never runs
- The reflexion/gap-filling pipeline is gated by `const isVesselQuery = /\b(imo|mmsi)\b/.test(qLower) || /\b([a-z]+(?:\s+[a-z]+)*\s+\d{1,3})\b/i.test(qLower);` (lines 761‚Äì764). Generic prompts like ‚Äúbig Danish cargo vessel‚Äù or ‚Äúlargest Bulgarian ship‚Äù don‚Äôt match, so the system never looks for missing IMO/MMSI/owner fields.

```760:765:functions/api/chatkit/agent-orchestrator.ts
const isVesselQuery = /\b(imo|mmsi)\b/.test(qLower) ||
  /\b([a-z]+(?:\s+[a-z]+)*\s+\d{1,3})\b/i.test(qLower);
const hasRegistrySource = rankedSources.some((s: any) =>
  /marinetraffic|vesselfinder|equasis/.test((s.url || '').toLowerCase()));
```

- **Impact:** Reflexion never fires for superlative queries, so the response omits IMO/MMSI/owner/operator even though the user explicitly asked for ‚Äúthe big vessel‚Äù.
- **Fix:** Introduce a semantic vessel classifier (look for words like ‚Äúcargo ship‚Äù, ‚Äútanker‚Äù, ‚Äúclass‚Äù, ‚ÄúTEU‚Äù) and run reflexion whenever the synthesizer emits ‚ÄúNot found‚Äù for critical fields.

### 3.4 Chain-of-thought is generated but always suppressed
- The SSE handler sets `const EMIT_THINKING_EVENTS = false` (line 2769) and short-circuits every status emitter when the flag is false. Simultaneously, the token parser strips `<thinking>` chunks from the streamed content (`continue;` at lines 2911‚Äì2953). The combination guarantees that **thinking never reaches the UI** even if the model follows the prompt.

```2769:2799:functions/api/chatkit/agent-orchestrator.ts
const EMIT_THINKING_EVENTS = false;
...
const statusEmitter = (event) => {
  if (!EMIT_THINKING_EVENTS) {
    lastStatusTime = Date.now();
    return;
  }
  controller.enqueue(...);
};
```

```2911:2953:functions/api/chatkit/agent-orchestrator.ts
if (chunk.includes('<thinking>')) thinkingInProgress = true;
if (thinkingInProgress) {
  thinkingBuffer += chunk;
  if (chunk.includes('</thinking>')) {
    statusEmitter?.({ type: 'thinking_complete', content: ... });
    thinkingBuffer = '';
    continue; // remove <thinking> from stream
  }
  continue; // partial thinking also swallowed
}
```

- **Fix:** Set `EMIT_THINKING_EVENTS = true` (or gate by user preference) and stop stripping `<thinking>` tokens when `statusEmitter` is disabled. Alternatively, emit thinking as markdown text if the UI cannot consume SSE events yet.

### 3.5 Citations lose hyperlinks
- `convertLegacyCitations` rewrites both `[[N]](url)` and `[N](url)` to `[N]` with no hyperlink (lines 70‚Äì78). Users therefore see footnote numbers without click targets.

```70:78:functions/api/chatkit/citation-formatter.ts
let converted = content.replace(/\[\[(\d+)\]\]\([^)]+\)/g, '[$1]');
converted = converted.replace(/\[(\d+)\]\([^)]+\)/g, '[$1]');
```

- **Fix:** Preserve markdown links or render `[N](url)` while still appending the `## REFERENCES` block. The ‚Äúpanel shows URLs‚Äù assumption is false in chat-only contexts.

### 3.6 Dead / unused subsystems increase risk
- **Verification pipeline:** 900+ lines in `verification-system.ts` are imported but never called; the guard at lines 1167‚Äì1225 in `agent-orchestrator.ts` is unreachable. This bloat confuses telemetry and increases bundle size.
- **Semantic cache:** `semantic-cache.ts` implements embedding-based caching but is never imported; all cache hits rely on exact string hashing, so variants like ‚Äúspecs‚Äù vs ‚Äúspecifications‚Äù are cache misses.
- **Status telemetry:** 55+ `statusEmitter` calls exist, but `EMIT_THINKING_EVENTS` disables them globally. The code complexity remains while functionality is zero.

---

## 4. Benchmark vs. Modern Maritime Agents

| Capability | Modern Baseline | Current State | Gap |
|------------|-----------------|---------------|-----|
| **Plan ‚Üí Act ‚Üí Critique loops** | OceanAI-style agents orchestrate multi-step reasoning (Tree-of-Thought, tool chains) for maritime planning ([OceanAI](https://oceanai.ai/blog/how-next-gen-ai-is-powering-maritime-innovation/)). | Single LangGraph loop with optional reflexion; plan-and-solve rarely triggers. | Add deterministic planning node plus critique/refinement passes even for non-vessel queries. |
| **Explainability / XAI** | Vibylabs and Marcura emphasise transparent reasoning and human-in-the-loop approvals ([Vibylabs](https://www.vibylabs.com/ai-knowledge-agents-in-maritime-operations/), [Marcura](https://marcura.com/blog/anchoring-the-future)). | CoT exists but is hidden; no user-facing confidence or rationale beyond plain text. | Surface thinking, provide confidence tiers, and allow operators to approve/flag outputs. |
| **Tool diversity** | Windward vertical AI agents combine AIS, weather, emissions, compliance feeds ([Windward](https://windward.ai/blog/how-ai-powers-maritime-operations/)). | Only Gemini (Google search) plus Tavily fallback; no sensor, AIS or regulatory APIs integrated. | Expand toolset (AIS feeds, class society APIs, regulatory DBs) with dynamic selection. |
| **Security & Reliability** | Industry guidance stresses cybersecurity, adversarial robustness, and red teaming ([CMR Berkeley](https://cmr.berkeley.edu/2024/12/utilizing-ai-for-maritime-transport-optimization/), [MDPI](https://www.mdpi.com/2079-9292/14/9/1844)). | No adversarial validation, no runtime policy enforcement beyond basic input filters. | Introduce anomaly detection on tool outputs and red-team style evaluation harness. |
| **Predictive intelligence** | Modern agents incorporate RL/predictive maintenance analytics ([IMARE](https://imare.in/wp-content/uploads/2025/02/22-AI-and-digital-transformation-in-the-maritime-industry-the-case-of-predictive-maintenance_Joseph-Morelos.pdf)). | Agent is purely retrieval/synthesis; no predictive modeling or sensor ingestion. | Align roadmap with predictive maintenance modules already documented in fleetcore marketing. |

---

## 5. Remediation Roadmap

| Priority | Issue | Recommended Fix | Effort | Verification |
|----------|-------|-----------------|--------|--------------|
| P0 | Research toggle ignored | Decouple browsing toggle from technical depth; introduce comparative & intent-based routing; add telemetry when deep research fires. | 1 day | Regression queries: ‚Äúbiggest Bulgarian vessel‚Äù, ‚Äúwho owns Dynamic 17‚Äù, ensure Tavily hits when browsing on. |
| P0 | CoT hidden / SSE suppressed | Enable thinking events, guard by feature flag, and stop stripping `<thinking>` tokens when events are disabled. | 0.5 day | Manual test: verify `thinking_start/thinking_complete` SSE events reach UI; ensure markdown fallback works. |
| P1 | Comparative/vessel detection gaps | Expand regexes + add semantic classifiers so reflexion/plan-solve run on qualitative prompts. | 1 day | Add unit tests for `selectCoTTechnique` and vessel detector; run scenario ‚Äúlargest Danish cargo vessel‚Äù. |
| P1 | Citations not clickable | Preserve `[N](url)` inline links while still adding references block. | 0.5 day | Snapshot output to confirm clickable numbers pointing to research URLs. |
| P2 | Dead systems & cache misses | Remove unused verification pipeline, integrate `semantic-cache`, and expose status telemetry toggles. | 1.5 days | Bench cache hit % before/after; verify bundle size drop once dead code removed. |
| P2 | Feature parity gaps | Add plan‚Üíact‚Üícritique loop (e.g., structured evaluation node), integrate AIS/compliance tools, and surface confidence indicators publicly. | 2‚Äì3 sprints | Compare capabilities checklist against Windward/OceanAI baseline; run user interviews. |

---

## 6. Verification Checklist
1. **Comparative Query Testpack:**  
   - ‚Äúwhis is the big danish cargo vessel‚Äù  
   - ‚Äúlargest Bulgarian cargo ship‚Äù  
   Expectation: plan-and-solve reasoning, reflexion fills IMO/MMSI/owner, Tavily invoked when browsing on.
2. **Research Toggle:** Same query with browsing off vs on should show distinct tool usage in logs (Gemini only vs Gemini+Tavily).
3. **CoT Streaming:** Inspect SSE feed for `thinking_start/thinking_complete` events and confirm UI renders reasoning.
4. **Citation UX:** Verify `[1](url)` inline links remain clickable while `## REFERENCES` enumerates domains.
5. **Cache Behavior:** Re-run query with synonyms (‚Äúbig Danish cargo vessel‚Äù vs ‚Äúlargest Danish cargo ship‚Äù) and ensure semantic cache hits after integration.

---

**Next Actions**
1. Implement routing + CoT fixes (P0) so the agent finally leverages Tavily and exposes reasoning.
2. Schedule a focused benchmarking sprint to integrate AIS/compliance feeds and match Windward/OceanAI capabilities.
3. Stand up telemetry dashboards for tool usage, reflexion iterations, and citation density so regressions are obvious without manual log diving.

---

## 7. Additional System Inventory (Step 1 Findings)

- **Dormant verification pipeline:** `agent-orchestrator.ts` still imports the full verification stack even though the downstream branch is unreachable.

```96:104:functions/api/chatkit/agent-orchestrator.ts
import { 
  verifyAndAnswer as verificationPipeline,
  extractEntities,
  normalizeData,
  performComparativeAnalysis,
  extractClaims,
  verifyClaims
} from './verification-system';
```

  *Opportunity:* Archive or fully wire this module (entity normalization, claim verification) as a dedicated ‚Äúfact checker‚Äù specialist instead of paying the bundling cost for unused code.

- **Semantic cache parked:** `functions/api/chatkit/semantic-cache.ts` already implements embedding-based caching with OpenAI `text-embedding-3-small`, but there are zero imports in the orchestrator. Activating it would reduce duplicate Gemini calls and stabilize comparative queries phrased differently.

- **Thinking telemetry disabled at runtime:** even after strengthening prompts, `EMIT_THINKING_EVENTS` stays `false`, so none of the 55+ status emitters reach the UI. This is low-hanging fruit for immediate transparency gains.

- **Legacy LangGraph agents + `_legacy_chat.ts`:** 6k+ LOC remain inside `functions/api/chatkit/legacy/`. They are ‚Äúreference only‚Äù but introduce confusion when engineers search for symbols like `routerNode`.

---

## 8. Fresh Industry Research (Step 2)

- **Plan‚ÄìAct‚ÄìReflect frameworks:** The ProSEA multi-agent architecture pairs a Manager agent with iterative Expert agents that explore, critique, and replan collaboratively ([arXiv:2510.07423](https://arxiv.org/abs/2510.07423)). This directly maps to our need for deterministic plan steps instead of a single LangGraph pass.
- **Factored agents:** Separating high-level planning from tool-format memorization improves robustness under long sessions and limits prompt bloat ([arXiv:2503.22931](https://arxiv.org/abs/2503.22931)). We can mirror this via ‚ÄúPlanner LLM + Executor LLM‚Äù rather than one monolith.
- **RefAgent & multi-agent refactoring workflows:** RefAgent (arXiv:2511.03153) and Kinde‚Äôs multi-agent pipelines show how specialized agents (parser, refactorer, validator) reduce regressions when modernizing large codebases ([Kinde multi-agent workflows](https://kinde.com/learn/ai-for-software-engineering/ai-agents/multi-agent-workflows-for-complex-refactoring-orchestrating-ai-teams/)).
- **Explainability & human-in-the-loop:** Maritime-focused copilots from Vibylabs and Marcura keep explainable outputs front-and-center, exposing confidence plus operator approval paths ([Vibylabs](https://www.vibylabs.com/ai-knowledge-agents-in-maritime-operations/), [Marcura](https://marcura.com/blog/anchoring-the-future)).
- **Security, data quality, and governance:** CMR Berkeley highlights fragmented maritime datasets, cross-border privacy, and the need for robust cyber defenses in AI deployments, while MDPI documents adversarial attacks on maritime AI sensors ([CMR Berkeley](https://cmr.berkeley.edu/2024/12/utilizing-ai-for-maritime-transport-optimization/), [MDPI](https://www.mdpi.com/2079-9292/14/9/1844)).
- **Operational observability:** Azure‚Äôs Agent Factory best practices and Amplework‚Äôs debugging guide emphasize time-travel snapshots, intent tracking, and action logs as mandatory for diagnosing agent behavior ([Azure observability](https://azure.microsoft.com/en-us/blog/agent-factory-top-5-agent-observability-best-practices-for-reliable-ai/), [Amplework debugging](https://www.amplework.com/blog/debugging-agentic-ai-tools-techniques/)).
- **Prompt-security guardrails:** Skywork‚Äôs prompt-triggering guidance and Agent.ai‚Äôs knowledge-agent best practices recommend RBAC, input sanitization, and structured output validation to prevent unsafe tool invocations ([Skywork security](https://skywork.ai/blog/ai-agent/best-practices-skill-triggering-prompts-invocation-debugging/), [Agent.ai best practices](https://docs.agent.ai/knowledge-agents/best-practices/)).

---

## 9. Gap & Opportunity Catalog (Step 3)

| Category | Missed Capability | Existing Asset to Leverage | Impact |
| --- | --- | --- | --- |
| **Architecture** | No plan‚Üíact‚Üícritique loop; single-pass LangGraph | LangGraph already modular + reflexion utilities | Enables deterministic decompositions, better comparative answers |
| **Tooling** | Only Gemini/Tavily; no AIS, class, or compliance APIs | `executeParallelQueries` abstraction already supports more connectors | Unlocks registry, weather, emissions, and OEM feeds similar to Windward |
| **Caching & Cost** | Semantic cache unused; KV hash-only | `semantic-cache.ts` ready to drop in | Reduces duplicate Gemini/Tavily usage, improves responsiveness |
| **Explainability & UX** | Thinking suppressed, no confidence messaging | Status emitter framework + `confidence-indicators.ts` | Aligns with Vibylabs/Marcura-style trust surfaces |
| **Security & Compliance** | Minimal RBAC, no prompt-injection shield, no data provenance | `input-security.ts` + Cloudflare Workers middleware | Supports Skywork/CMR/MDPI guidelines, required for enterprise buyers |
| **Observability** | Logs only; no structured traces or time-travel snapshots | Existing LangSmith wiring, SSE events | Critical for Azure-style agent factory governance and debugging |
| **Legacy Debt** | Dead verification pipeline & legacy agents | `verification-system.ts`, `legacy/` tree | Either delete or revive as modular fact-checker to reduce confusion |

---

## 10. Phased Refactoring Blueprint (Step 4)

### Phase 0 ‚Äì Stabilize & Surface (1 sprint)
- Re-enable thinking/status SSE (`EMIT_THINKING_EVENTS` flag) with user preference gating.
- Loosen classification gating: treat comparative adjectives + browsing toggle as research triggers.
- Integrate semantic cache wrapper before executing Gemini/Tavily.
- Remove or feature-flag the unused verification pipeline; archive `legacy/` tree.
- Deliverable: telemetry dashboard showing tool selection, CoT event rate, cache hit rate.

### Phase 1 ‚Äì Architectural Foundations (1‚Äì2 sprints)
- Introduce Planner vs. Executor split (inspired by factored agents) so comparative and technical queries always emit an explicit plan before synthesis.
- Add lightweight ‚ÄúCritic‚Äù node that validates owner/operator completeness using the existing gap analyzer before final streaming.
- Wire the semantic cache into `executeParallelQueries` and route high-similarity hits to skip redundant network calls.
- Deliverable: deterministic plan traces, automatic critique corrections (owner/IMO) >90% coverage.

### Phase 2 ‚Äì Capability Expansion & Trust (2+ sprints)
- Add new specialized tools (AIS/registry API, class society data, regulatory PDFs, OEM manuals). Extend `executeParallelQueries` plan items with tool-specific schema.
- Implement RBAC + prompt-sanitization layer per Skywork guidance; require human approval for high-risk actions (deleting sessions, sending emails).
- Stand up observability stack: store time-travel snapshots (Azure/Amplework patterns), expose dashboards for intent drift, action counts, and latency budgets.
- Deliverable: parity checklist vs. Windward/OceanAI with verifiable compliance stories.

### Phase 3 ‚Äì Predictive & Proactive Intelligence (roadmap)
- Integrate predictive maintenance knowledge (IMARE) and anomaly detection from MDPI research to move beyond retrieval.
- Launch self-evaluation loops (RefAgent-style) for long-form maintenance reports, enabling autonomous edits before presentation.
- Deliverable: measurable reduction in manual follow-ups, introduction of ‚Äúfleet risk‚Äù scores grounded in multi-source data.

---

## 11. Validation & Telemetry Additions (Step 5)

1. **Tool/plan telemetry:** Emit structured JSON events for plan nodes, executed tools, cache hits, and critic interventions; push to LangSmith or Datadog for dashboards.
2. **Security auditing:** Log prompt-injection detections, sanitization actions, and RBAC checks to satisfy enterprise governance requests (ties back to Skywork guidance).
3. **Data quality metrics:** Track coverage of IMO/MMSI/owner/operator plus source tiers; alert when <85% completeness for vessel queries as mandated by CMR data-quality learnings.
4. **Observability runbooks:** Adopt Azure-style time-travel debugging by storing key state snapshots whenever reflexion triggers or when the critic overrides the synthesizer.

These additions ensure the phased refactor remains testable, auditable, and aligned with the maritime AI leaders identified in Step 2.

---

## Phase 0 Audit (Current State ‚Äì November 17, 2025)

- **Thinking telemetry intentionally disabled:** The stream handler hardcodes `const EMIT_THINKING_EVENTS = false`, so every `statusEmitter` call short-circuits and no CoT/status telemetry ever reaches the UI.  
```2769:2799:functions/api/chatkit/agent-orchestrator.ts
const EMIT_THINKING_EVENTS = false;
...
if (!EMIT_THINKING_EVENTS) {
  lastStatusTime = Date.now();
  return;
}
```

- **Browsing toggle still routes to verification:** Even with `enableBrowsing = true`, the classifier returns verification unless the query simultaneously has an entity **and** high technical depth. Browsing therefore never triggers the dedicated research node.  
```500:507:functions/api/chatkit/query-classification-rules.ts
if (enableBrowsing && (hasEntity || needsTechnicalDepth)) {
  console.log(`   ‚úÖ PRIORITY 1: Research toggle enabled + entity/technical query`);
  console.log(`   üîç VERIFICATION MODE: Gemini search for detailed information`);
  return { mode: 'verification', ... };
}
```

- **Logs still claim research mode is disabled:** The classification log prints `RESEARCH MODE - Deep multi-source (DISABLED)`, reinforcing the earlier behavior.  
```809:813:functions/api/chatkit/query-classification-rules.ts
const modeDescription = {
  'none': 'KNOWLEDGE MODE - Training data',
  'verification': 'VERIFICATION MODE - Gemini grounding',
  'research': 'RESEARCH MODE - Deep multi-source (DISABLED)'
};
```

- **Semantic cache only fires when OpenAI key + KV both exist:** The planner calls `getSemanticCachedResult` but immediately bails if either dependency is missing, so in the current worker deployment (no OpenAI key) the semantic path is effectively off.  
```674:685:functions/api/chatkit/query-planner.ts
if (openaiApiKey && kv) {
  const semanticMatch = await getSemanticCachedResult(
    kv,
    enrichedQuery,
    entityContext,
    openaiApiKey,
    getDefaultSemanticCacheConfig()
  );
```

- **Verification pipeline still bundled:** `verification-system.ts` (900+ LOC) is imported solely for `extractEntities`, keeping the dead pipeline in the bundle even though `verificationPipeline` is never called.  
```96:104:functions/api/chatkit/agent-orchestrator.ts
import {
  verifyAndAnswer as verificationPipeline,
  extractEntities,
  normalizeData,
  performComparativeAnalysis,
  extractClaims,
  verifyClaims
} from './verification-system';
```

- **Legacy LangGraph agents remain in production tree:** `functions/api/chatkit/legacy/_legacy_chat.ts` (>2,600 LOC) and `_legacy-langgraph-agent.ts` (>3,500 LOC) are still shipped, increasing search noise and bundle size even though they‚Äôre unused.

**Conclusion:** Phase 0 must (1) re-enable thinking/status telemetry, (2) honor the browsing toggle by actually entering research mode, (3) ensure semantic caching and top-level caches are reachable regardless of environment configuration, and (4) gate or remove unused heavy modules so later phases can build on a clean baseline.

---

## Phase 1 Audit (Planner / Critic Readiness)

- **No dedicated planner/executor split:** `routerNode` calls `planQuery`, immediately truncates to 10 sub-queries, and streams tokens straight into synthesis; there is no separate state node to persist plan traces or allow replanning.  
```640:657:functions/api/chatkit/agent-orchestrator.ts
const queryPlan = await planQuery(queryToSend, entityContext, env.OPENAI_API_KEY);
const prioritized = [...queryPlan.subQueries].sort(...);
const budgetedSubQueries = prioritized.slice(0, MAX_SUBQUERIES);
await emitPlanThinkingStepsLLM({ strategy: queryPlan.strategy, subQueries: budgetedSubQueries as any }, statusEmitter, env.OPENAI_API_KEY);
```

- **Reflexion is gated and optional; no universal critic:** Gap analysis only runs when `isVesselQuery` matches strict IMO/MMSI patterns, and even then the while-loop can exit without re-validating before the final response‚Äîthere‚Äôs no final ‚Äúcritic‚Äù pass ensuring IMO/MMSI/owner/operator are present.  
```760:905:functions/api/chatkit/agent-orchestrator.ts
const isVesselQuery = /\b(imo|mmsi)\b/.test(qLower) || /\b([a-z]+(?:\s+[a-z]+)*\s+\d{1,3})\b/i.test(qLower);
...
while (reflexionIteration < MAX_REFLEXION_ITERATIONS) {
  const validation = validateVesselEntity(queryToSend, minimal);
  ...
  if (!needsRefine) break;
  // generate followups ‚Üí executeParallelQueries ‚Üí merge
}
```

**Phase 1 needs:** (a) a first-class planner node whose output is persisted and explainable, (b) a critic stage that runs regardless of vessel detection to enforce critical-field completeness, and (c) tighter reflexion triggers that don‚Äôt rely solely on IMO/MMSI heuristics.

---

## Phase 2 Audit (Trust, Security, Tooling)

- **Security/RBAC is shallow:** The only guard is `performSecurityCheck` on user input; there is no role-based access control, prompt sanitization, or output validation before sensitive actions (Skywork best practices recommend RBAC + output validation for live agents).  
```70:104:functions/api/chatkit/chat.ts
const securityCheck = performSecurityCheck(
  lastUserMessage.content,
  sessionId,
  { maxRequests: 10, windowMs: 60000, strictMode: false }
);
```

- **No observability beyond console logs:** Azure/Amplework guidance emphasizes time-travel snapshots, action logging, and intent tracking, but we currently only log to console and optionally emit SSE thinking events‚Äîno persisted traces or dashboards.

- **Tool surface limited to Gemini/Tavily:** Industry leaders (Windward, OceanAI) combine AIS, class society rules, OEM PDFs, and compliance feeds; our tool registry only exposes Gemini search, Tavily deep-research, and a static knowledge base (`tools/index.ts`).

- **Predictive intelligence absent:** There is no integration with maintenance sensors or anomaly detection despite available research (IMARE, MDPI). Reflexion is purely retrieval-based.

Phase 2 should therefore: (1) add RBAC/prompt-hardening middleware, (2) wire structured telemetry (planning traces, tool invocations, critic alerts) into an observability sink, and (3) expand the toolset with AIS/compliance/OEM connectors plus guardrails to keep them trustworthy.

